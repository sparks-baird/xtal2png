
@article{gomez-bombarelliAutomaticChemicalDesign2016,
  title = {Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules},
  author = {{G{\'o}mez-Bombarelli}, Rafael and Wei, Jennifer N. and Duvenaud, David and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel and {S{\'a}nchez-Lengeling}, Benjam{\'i}n and Sheberla, Dennis and {Aguilera-Iparraguirre}, Jorge and Hirzel, Timothy D. and Adams, Ryan P. and {Aspuru-Guzik}, Al{\'a}n},
  year = {2016},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1610.02415},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Chemical Physics (physics.chem-ph),FOS: Computer and information sciences,FOS: Physical sciences,Machine Learning (cs.LG)}
}

@article{gomez-bombarelliAutomaticChemicalDesign2018,
  title = {Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules},
  author = {{G{\'o}mez-Bombarelli}, Rafael and Wei, Jennifer N. and Duvenaud, David and {Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel and {S{\'a}nchez-Lengeling}, Benjam{\'i}n and Sheberla, Dennis and {Aguilera-Iparraguirre}, Jorge and Hirzel, Timothy D. and Adams, Ryan P. and {Aspuru-Guzik}, Al{\'a}n},
  year = {2018},
  month = feb,
  journal = {ACS Central Science},
  volume = {4},
  number = {2},
  eprint = {1610.02415},
  eprinttype = {arxiv},
  primaryclass = {physics},
  pages = {268--276},
  issn = {2374-7943, 2374-7951},
  doi = {10.1021/acscentsci.7b00572},
  abstract = {We report a method to convert discrete representations of molecules to and from a multidimensional continuous representation. This generative model allows efficient search and optimization through open-ended spaces of chemical compounds.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Physics - Chemical Physics},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\2JMZE9VY\\GÃ³mez-Bombarelli et al. - 2018 - Automatic chemical design using a data-driven cont.pdf}
}

@article{goodallPredictingMaterialsProperties2019,
  title = {Predicting Materials Properties without Crystal Structure: {{Deep}} Representation Learning from Stoichiometry},
  author = {Goodall, Rhys E. A. and Lee, Alpha A.},
  year = {2019},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1910.00617},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Computational Physics (physics.comp-ph),FOS: Computer and information sciences,FOS: Physical sciences,Machine Learning (cs.LG),Materials Science (cond-mat.mtrl-sci)}
}

@article{goodallPredictingMaterialsProperties2020,
  title = {Predicting Materials Properties without Crystal Structure: {{Deep}} Representation Learning from Stoichiometry},
  shorttitle = {Predicting Materials Properties without Crystal Structure},
  author = {Goodall, Rhys E. A. and Lee, Alpha A.},
  year = {2020},
  month = dec,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  eprint = {1910.00617},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, physics:physics},
  pages = {6280},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-19964-7},
  abstract = {Machine learning has the potential to accelerate materials discovery by accurately predicting materials properties at a low computational cost. However, the model inputs remain a key stumbling block. Current methods typically use descriptors constructed from knowledge of either the full crystal structure -- therefore only applicable to materials with already characterised structures -- or structure-agnostic fixed-length representations hand-engineered from the stoichiometry. We develop a machine learning approach that takes only the stoichiometry as input and automatically learns appropriate and systematically improvable descriptors from data. Our key insight is to treat the stoichiometric formula as a dense weighted graph between elements. Compared to the state of the art for structure-agnostic methods, our approach achieves lower errors with less data.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Materials Science,Physics - Computational Physics},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\IF6WR9YR\\Goodall and Lee - 2020 - Predicting materials properties without crystal st.pdf}
}

@misc{kingmaAutoEncodingVariationalBayes2014a,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  year = {2014},
  month = may,
  number = {arXiv:1312.6114},
  eprint = {1312.6114},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\57YKTW4W\\Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.pdf}
}

@misc{kipfSemisupervisedClassificationGraph2016,
  title = {Semi-Supervised Classification with Graph Convolutional Networks},
  author = {Kipf, Thomas N. and Welling, Max},
  year = {2016},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1609.02907},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)}
}

@article{ongPythonMaterialsGenomics2013,
  title = {Python {{Materials Genomics}} (Pymatgen): {{A}} Robust, Open-Source Python Library for Materials Analysis},
  shorttitle = {Python {{Materials Genomics}} (Pymatgen)},
  author = {Ong, Shyue Ping and Richards, William Davidson and Jain, Anubhav and Hautier, Geoffroy and Kocher, Michael and Cholia, Shreyas and Gunter, Dan and Chevrier, Vincent L. and Persson, Kristin A. and Ceder, Gerbrand},
  year = {2013},
  month = feb,
  journal = {Computational Materials Science},
  volume = {68},
  pages = {314--319},
  issn = {09270256},
  doi = {10.1016/j.commatsci.2012.10.028},
  abstract = {We present the Python Materials Genomics (pymatgen) library, a robust, open-source Python library for materials analysis. A key enabler in high-throughput computational materials science efforts is a robust set of software tools to perform initial setup for the calculations (e.g., generation of structures and necessary input files) and post-calculation analysis to derive useful material properties from raw calculated data. The pymatgen library aims to meet these needs by (1) defining core Python objects for materials data representation, (2) providing a well-tested set of structure and thermodynamic analyses relevant to many applications, and (3) establishing an open platform for researchers to collaboratively develop sophisticated analyses of materials data obtained both from first principles calculations and experiments. The pymatgen library also provides convenient tools to obtain useful materials data via the Materials Project's REpresentational State Transfer (REST) Application Programming Interface (API). As an example, using pymatgen's interface to the Materials Project's RESTful API and phasediagram package, we demonstrate how the phase and electrochemical stability of a recently synthesized material, Li4SnS4, can be analyzed using a minimum of computing resources. We find that Li4SnS4 is a stable phase in the Li\textendash Sn\textendash S phase diagram (consistent with the fact that it can be synthesized), but the narrow range of lithium chemical potentials for which it is predicted to be stable would suggest that it is not intrinsically stable against typical electrodes used in lithium-ion batteries.},
  langid = {english},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\GUGQ4GNV\\Ong et al. - 2013 - Python Materials Genomics (pymatgen) A robust, op.pdf}
}

@misc{Pythonista2021,
  title = {Pythonista},
  year = {2021},
  month = nov,
  journal = {Wiktionary},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 64674604},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\8AMZF6UQ\\Pythonista.html}
}

@article{renInvertibleCrystallographicRepresentation2022a,
  title = {An Invertible Crystallographic Representation for General Inverse Design of Inorganic Crystals with Targeted Properties},
  author = {Ren, Zekun and Tian, Siyu Isaac Parker and Noh, Juhwan and Oviedo, Felipe and Xing, Guangzong and Li, Jiali and Liang, Qiaohao and Zhu, Ruiming and Aberle, Armin G. and Sun, Shijing and Wang, Xiaonan and Liu, Yi and Li, Qianxiao and Jayavelu, Senthilnath and Hippalgaonkar, Kedar and Jung, Yousung and Buonassisi, Tonio},
  year = {2022},
  month = jan,
  journal = {Matter},
  volume = {5},
  number = {1},
  pages = {314--335},
  issn = {2590-2385},
  doi = {10.1016/j.matt.2021.11.032},
  abstract = {Realizing general inverse design could greatly accelerate the discovery of new materials with user-defined properties. However, state-of-the-art generative models tend to be limited to a specific composition or crystal structure. Herein, we present a framework capable of general inverse design (not limited to a given set of elements or crystal structures), featuring a generalized invertible representation that encodes crystals in both real and reciprocal space, and a property-structured latent space from a variational autoencoder (VAE). In three design cases, the framework generates 142 new crystals with user-defined formation energies, bandgap, thermoelectric (TE) power factor, and combinations thereof. These generated crystals, absent in the training database, are validated by first-principles calculations. The success rates (number of first-principles-validated target-satisfying crystals/number of designed crystals) ranges between 7.1\% and 38.9\%. These results represent a significant step toward property-driven general inverse design using generative models, although practical challenges remain when coupled with experimental synthesis.},
  langid = {english},
  keywords = {general inverse design,generalized crystallographic representation,generative model,invertible crystallographic representation,machine learning,property-structured latent space,solid-state materials,thermoelectrics,variational autoencoder},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\C597QIUA\\Ren et al_2022_An invertible crystallographic representation for general inverse design of.pdf;C\:\\Users\\sterg\\Zotero\\storage\\3A7B58GN\\S2590238521006251.html}
}

@misc{riebesellPymatviz2022,
  title = {Pymatviz},
  author = {Riebesell, Janosh},
  year = {2022},
  month = jun,
  abstract = {A toolkit for visualizations in materials informatics.},
  copyright = {MIT},
  keywords = {data-visualization,machine-learning,materials-informatics,matplotlib,plotly,plots,uncertainty,uncertainty-calibration}
}

@inproceedings{sahariaPaletteImagetoImageDiffusion2022a,
  title = {Palette: {{Image-to-Image Diffusion Models}}},
  shorttitle = {Palette},
  booktitle = {Special {{Interest Group}} on {{Computer Graphics}} and {{Interactive Techniques Conference Proceedings}}},
  author = {Saharia, Chitwan and Chan, William and Chang, Huiwen and Lee, Chris and Ho, Jonathan and Salimans, Tim and Fleet, David and Norouzi, Mohammad},
  year = {2022},
  month = aug,
  pages = {1--10},
  publisher = {{ACM}},
  address = {{Vancouver BC Canada}},
  doi = {10.1145/3528233.3530757},
  isbn = {978-1-4503-9337-9},
  langid = {english},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\KXPL42QN\\Saharia et al. - 2022 - Palette Image-to-Image Diffusion Models.pdf}
}

@misc{selfies,
  title = {{{SELFIES}} and the Future of Molecular String Representations},
  author = {Krenn, Mario and Ai, Qianxiang and Barthel, Senja and Carson, Nessa and Frei, Angelo and Frey, Nathan C. and Friederich, Pascal and Gaudin, Th{\'e}ophile and Gayle, Alberto Alexander and Jablonka, Kevin Maik and Lameiro, Rafael F. and Lemm, Dominik and Lo, Alston and Moosavi, Seyed Mohamad and {N{\'a}poles-Duarte}, Jos{\'e} Manuel and Nigam, AkshatKumar and Pollice, Robert and Rajan, Kohulan and Schatzschneider, Ulrich and Schwaller, Philippe and Skreta, Marta and Smit, Berend and {Strieth-Kalthoff}, Felix and Sun, Chong and Tom, Gary and {von Rudorff}, Guido Falk and Wang, Andrew and White, Andrew and Young, Adamo and Yu, Rose and {Aspuru-Guzik}, Al{\'a}n},
  year = {2022},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2204.00056},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Chemical Physics (physics.chem-ph),FOS: Computer and information sciences,FOS: Physical sciences,Machine Learning (cs.LG)}
}

@misc{sohl-dicksteinDeepUnsupervisedLearning2015,
  title = {Deep {{Unsupervised Learning}} Using {{Nonequilibrium Thermodynamics}}},
  author = {{Sohl-Dickstein}, Jascha and Weiss, Eric A. and Maheswaranathan, Niru and Ganguli, Surya},
  year = {2015},
  month = nov,
  number = {arXiv:1503.03585},
  eprint = {1503.03585},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, q-bio, stat},
  publisher = {{arXiv}},
  abstract = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\URNJF3FV\\Sohl-Dickstein et al. - 2015 - Deep Unsupervised Learning using Nonequilibrium Th.pdf}
}

@misc{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2017},
  month = dec,
  number = {arXiv:1706.03762},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\2TR7873X\\Vaswani et al. - 2017 - Attention Is All You Need.pdf}
}

@article{wangCompositionallyRestrictedAttentionbased2021,
  title = {Compositionally Restricted Attention-Based Network for Materials Property Predictions},
  author = {Wang, Anthony Yu-Tung and Kauwe, Steven K. and Murdock, Ryan J. and Sparks, Taylor D.},
  year = {2021},
  month = dec,
  journal = {npj Computational Materials},
  volume = {7},
  number = {1},
  pages = {77},
  issn = {2057-3960},
  doi = {10.1038/s41524-021-00545-1},
  abstract = {Abstract             In this paper, we demonstrate an application of the Transformer self-attention mechanism in the context of materials science. Our network, the Compositionally Restricted Attention-Based network (), explores the area of structure-agnostic materials property predictions when only a chemical formula is provided. Our results show that 's performance matches or exceeds current best-practice methods on nearly all of 28 total benchmark datasets. We also demonstrate how 's architecture lends itself towards model interpretability by showing different visualization approaches that are made possible by its design. We feel confident that  and its attention-based framework will be of keen interest to future materials informatics researchers.},
  langid = {english},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\APW9NK4X\\Wang et al. - 2021 - Compositionally restricted attention-based network.pdf}
}

@article{wangCompositionallyrestrictedAttentionbasedNetwork2020,
  title = {Compositionally-Restricted Attention-Based Network for Materials Property Prediction},
  author = {Wang, Anthony and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor},
  year = {2020},
  month = feb,
  publisher = {{American Chemical Society (ACS)}},
  doi = {10.26434/chemrxiv.11869026.v1}
}

@article{weiningerSMILESChemicalLanguage1988,
  title = {{{SMILES}}, a Chemical Language and Information System. 1. {{Introduction}} to Methodology and Encoding Rules},
  author = {Weininger, David},
  year = {1988},
  month = feb,
  journal = {Journal of Chemical Information and Computer Sciences},
  volume = {28},
  number = {1},
  pages = {31--36},
  publisher = {{American Chemical Society}},
  issn = {0095-2338},
  doi = {10.1021/ci00057a005},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\JDGWYLHJ\\Weininger_1988_SMILES, a chemical language and information system.pdf;C\:\\Users\\sterg\\Zotero\\storage\\ZL2984XI\\ci00057a005.html}
}

@misc{xieCrystalDiffusionVariational2021,
  title = {Crystal {{Diffusion Variational Autoencoder}} for {{Periodic Material Generation}}},
  author = {Xie, Tian and Fu, Xiang and Ganea, Octavian-Eugen and Barzilay, Regina and Jaakkola, Tommi},
  year = {2021},
  month = oct,
  number = {arXiv:2110.06197v1},
  eprint = {2110.06197v1},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, physics:physics},
  publisher = {{arXiv}},
  abstract = {Generating the periodic structure of stable materials is a long-standing challenge for the material design community. This task is difficult because stable materials only exist in a low-dimensional subspace of all possible periodic arrangements of atoms: 1) the coordinates must lie in the local energy minimum defined by quantum mechanics, and 2) global stability also requires the structure to follow the complex, yet specific bonding preferences between different atom types. Existing methods fail to incorporate these factors and often lack proper invariances. We propose a Crystal Diffusion Variational Autoencoder (CDVAE) that captures the physical inductive bias of material stability. By learning from the data distribution of stable materials, the decoder generates materials in a diffusion process that moves atomic coordinates towards a lower energy state and updates atom types to satisfy bonding preferences between neighbors. Our model also explicitly encodes interactions across periodic boundaries and respects permutation, translation, rotation, and periodic invariances. We significantly outperform past methods in three tasks: 1) reconstructing the input structure, 2) generating valid, diverse, and realistic materials, and 3) generating materials that optimize a specific property. We also provide several standard datasets and evaluation metrics for the broader machine learning community.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Materials Science,Physics - Computational Physics},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\AMTRUFLC\\Xie et al. - 2022 - Crystal Diffusion Variational Autoencoder for Peri.pdf}
}

@article{xieCrystalDiffusionVariational2022,
  title = {Crystal {{Diffusion Variational Autoencoder}} for {{Periodic Material Generation}}},
  author = {Xie, Tian and Fu, Xiang and Ganea, Octavian-Eugen and Barzilay, Regina and Jaakkola, Tommi},
  year = {2022},
  month = mar,
  journal = {arXiv:2110.06197 [cond-mat, physics:physics]},
  eprint = {2110.06197},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, physics:physics},
  abstract = {Generating the periodic structure of stable materials is a long-standing challenge for the material design community. This task is difficult because stable materials only exist in a low-dimensional subspace of all possible periodic arrangements of atoms: 1) the coordinates must lie in the local energy minimum defined by quantum mechanics, and 2) global stability also requires the structure to follow the complex, yet specific bonding preferences between different atom types. Existing methods fail to incorporate these factors and often lack proper invariances. We propose a Crystal Diffusion Variational Autoencoder (CDVAE) that captures the physical inductive bias of material stability. By learning from the data distribution of stable materials, the decoder generates materials in a diffusion process that moves atomic coordinates towards a lower energy state and updates atom types to satisfy bonding preferences between neighbors. Our model also explicitly encodes interactions across periodic boundaries and respects permutation, translation, rotation, and periodic invariances. We significantly outperform past methods in three tasks: 1) reconstructing the input structure, 2) generating valid, diverse, and realistic materials, and 3) generating materials that optimize a specific property. We also provide several standard datasets and evaluation metrics for the broader machine learning community.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Materials Science,Physics - Computational Physics},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\VBQ9U4WF\\Xie et al_2022_Crystal Diffusion Variational Autoencoder for Periodic Material Generation.pdf}
}

@article{xieCrystalGraphConvolutional2017,
  title = {Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties},
  author = {Xie, Tian and Grossman, Jeffrey C.},
  year = {2017},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1710.10324},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Physical sciences,Materials Science (cond-mat.mtrl-sci)}
}

@article{xieCrystalGraphConvolutional2018,
  title = {Crystal {{Graph Convolutional Neural Networks}} for an {{Accurate}} and {{Interpretable Prediction}} of {{Material Properties}}},
  author = {Xie, Tian and Grossman, Jeffrey C.},
  year = {2018},
  month = apr,
  journal = {Physical Review Letters},
  volume = {120},
  number = {14},
  eprint = {1710.10324},
  eprinttype = {arxiv},
  primaryclass = {cond-mat},
  pages = {145301},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.120.145301},
  abstract = {The use of machine learning methods for accelerating the design of crystalline materials usually requires manually constructed feature vectors or complex transformation of atom coordinates to input the crystal structure, which either constrains the model to certain crystal types or makes it difficult to provide chemical insights. Here, we develop a crystal graph convolutional neural networks framework to directly learn material properties from the connection of atoms in the crystal, providing a universal and interpretable representation of crystalline materials. Our method provides a highly accurate prediction of density functional theory calculated properties for eight different properties of crystals with various structure types and compositions after being trained with \$10\^4\$ data points. Further, our framework is interpretable because one can extract the contributions from local chemical environments to global properties. Using an example of perovskites, we show how this information can be utilized to discover empirical rules for materials design.},
  archiveprefix = {arXiv},
  keywords = {Condensed Matter - Materials Science},
  file = {C\:\\Users\\sterg\\Zotero\\storage\\SCUJG42Y\\Xie_Grossman_2018_Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable.pdf;C\:\\Users\\sterg\\Zotero\\storage\\SJQ6MXAE\\1710.html}
}

@misc{xtal2png,
  title = {Xtal2png: {{Encode}}/Decode a Crystal Structure to/from a Grayscale {{PNG}} Image for Direct Use with Image-Based Machine Learning Models Such as {{Palette}}.},
  author = {Baird, Sterling G. and Sayeed, Hasan M.},
  year = {2022},
  publisher = {{GitHub}}
}
